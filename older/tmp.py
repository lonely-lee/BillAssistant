import pandas as pd
import openpyxl
import tkinter.filedialog
import datetime
import numpy as np  # ç”¨äºåˆ›å»ºNaNå€¼

# äº¤æ˜“æ–¹å¼æ˜ å°„
expense_mapping = {  
    'æ”¶å…¥': 'æ”¶å…¥',  
    'æ”¯å‡º': 'æ”¯å‡º',  
    'ä¸è®¡æ”¶æ”¯': 'ä¸è®¡æ”¶æ”¯', 
    'å¾…å®š': 'å¾…å®š'
}
default_expense = 'å¾…å®š'  # æˆ–è€…é€‰æ‹©å…¶ä»–é»˜è®¤å€¼

# æ—¶é—´æ ¼å¼
format_str = '%Y-%m-%d %H:%M:%S'

# äº¤æ˜“çŠ¶æ€æ˜ å°„
transaction_status_mapping = {  
    'äº¤æ˜“æˆåŠŸ': 'äº¤æ˜“æˆåŠŸ',  
    'äº¤æ˜“å¤±è´¥': 'äº¤æ˜“å¤±è´¥',
    'å¾…å®š': 'å¾…å®š'  
}
default_transaction_status = 'å¾…å®š'  # æˆ–è€…é€‰æ‹©å…¶ä»–é»˜è®¤å€¼

def strip_in_data(data):  # æŠŠåˆ—åä¸­å’Œæ•°æ®ä¸­é¦–å°¾çš„ç©ºæ ¼éƒ½å»æ‰ã€‚
    data = data.rename(columns={column_name: column_name.strip() for column_name in data.columns})
    # å»é™¤å­—ç¬¦ä¸²ä¸­çš„ç‰¹æ®Šå­—ç¬¦
    col_5_type = data.iloc[:, 5].dtype
    if col_5_type == 'object':
        data.iloc[:, 5] = data.iloc[:, 5].str.strip().str.replace('Â¥', '')
        data.iloc[:, 5] = data.iloc[:, 5].astype('float64')
    elif col_5_type == 'float64':
        pass
    return data

def read_data_wx(path):  # è·å–å¾®ä¿¡æ•°æ®
    """
    åˆæ­¥è§£æå¾®ä¿¡è´¦å•æ•°æ®ï¼Œæå–æ‰€éœ€çš„åˆ—ï¼Œç»Ÿä¸€æ•°æ®æ ¼å¼
    """
    d_wx = pd.read_csv(path, skiprows=16, encoding='utf-8')  # æ•°æ®è·å–ï¼Œå¾®ä¿¡
    # print("beforeæˆåŠŸè¯»å– " + str(len(d_wx)) + " æ¡ã€Œå¾®ä¿¡ã€è´¦å•æ•°æ®\n")
    d_wx = d_wx.iloc[:, [0,1,2,3,4,5,6,7,8,10]]  # æŒ‰é¡ºåºæå–æ‰€éœ€åˆ—
    d_wx = strip_in_data(d_wx)  # å»é™¤åˆ—åä¸æ•°å€¼ä¸­çš„ç©ºæ ¼ã€‚
    d_wx.iloc[:, 0] = d_wx.iloc[:, 0].astype('datetime64[ns]')  # æ•°æ®ç±»å‹æ›´æ”¹
    # d_wx.iloc[:, 5] = d_wx.iloc[:, 5].astype('float64')  # æ•°æ®ç±»å‹æ›´æ”¹
    d_wx.rename(columns={'å½“å‰çŠ¶æ€': 'äº¤æ˜“çŠ¶æ€','æ”¯ä»˜æ–¹å¼': 'äº¤æ˜“æ–¹å¼', 'é‡‘é¢(å…ƒ)': 'é‡‘é¢'}, inplace=True)  # ä¿®æ”¹åˆ—åç§°

    d_wx['äº¤æ˜“æ—¶é—´'] = pd.to_datetime(d_wx['äº¤æ˜“æ—¶é—´']).dt.strftime(format_str)

    d_wx.insert(1, 'æ¥æº', "å¾®ä¿¡", allow_duplicates=True)  # æ·»åŠ å¾®ä¿¡æ¥æºæ ‡è¯†
    len1 = len(d_wx)
    print("æˆåŠŸè¯»å– " + str(len1) + " æ¡ã€Œå¾®ä¿¡ã€è´¦å•æ•°æ®\n")
    return d_wx

def read_data_zfb(path):  # è·å–æ”¯ä»˜å®æ•°æ®
    """
    åˆæ­¥è§£ææ”¯ä»˜å®æ•°æ®ï¼Œæå–æ‰€éœ€çš„åˆ—ï¼Œç»Ÿä¸€æ•°æ®æ ¼å¼
    """
    d_zfb = pd.read_csv(path, skiprows=24, encoding='gbk')  # æ•°æ®è·å–ï¼Œæ”¯ä»˜å® skiprowså¯¹åº”ç€åˆ—åè¡Œ
    d_zfb = d_zfb.iloc[:, [0,1,2,4,5,6,7, 8, 9,11]]  # æŒ‰é¡ºåºæå–æ‰€éœ€åˆ—
    d_zfb = strip_in_data(d_zfb)  # å»é™¤åˆ—åä¸æ•°å€¼ä¸­çš„ç©ºæ ¼ã€‚
    d_zfb.iloc[:, 0] = d_zfb.iloc[:, 0].astype('datetime64[ns]')  # æ•°æ®ç±»å‹æ›´æ”¹
    d_zfb.iloc[:, 5] = d_zfb.iloc[:, 5].astype('float64')  # æ•°æ®ç±»å‹æ›´æ”¹
    d_zfb.rename(columns={'äº¤æ˜“åˆ†ç±»': 'äº¤æ˜“ç±»å‹','å•†å“è¯´æ˜': 'å•†å“', 'æ”¶/ä»˜æ¬¾æ–¹å¼': 'äº¤æ˜“æ–¹å¼','äº¤æ˜“è®¢å•å·':'äº¤æ˜“å•å·'}, inplace=True)  # ä¿®æ”¹åˆ—åç§°

    d_zfb['äº¤æ˜“æ—¶é—´'] = pd.to_datetime(d_zfb['äº¤æ˜“æ—¶é—´']).dt.strftime(format_str)

    d_zfb.insert(1, 'æ¥æº', "æ”¯ä»˜å®", allow_duplicates=True)  # æ·»åŠ æ”¯ä»˜å®æ¥æºæ ‡è¯†
    len2 = len(d_zfb)
    print("æˆåŠŸè¯»å– " + str(len2) + " æ¡ã€Œæ”¯ä»˜å®ã€è´¦å•æ•°æ®\n")
    return d_zfb


def read_data_jd(file_path):
    df = pd.read_csv(file_path, skiprows=22, names=[  
        'äº¤æ˜“æ—¶é—´', 'äº¤æ˜“åˆ†ç±»', 'å•†æˆ·åç§°', 'äº¤æ˜“è¯´æ˜', 'æ”¶/æ”¯', 'é‡‘é¢', 'æ”¶/ä»˜æ¬¾æ–¹å¼', 'äº¤æ˜“çŠ¶æ€', 'äº¤æ˜“è®¢å•å·', 'å•†å®¶è®¢å•å·', 'å¤‡æ³¨'  
    ])
    df['äº¤æ˜“æ—¶é—´'] = df['äº¤æ˜“æ—¶é—´'].str.replace(r'\t', '', regex=True)
    # df['äº¤æ˜“æ—¶é—´'] = df['äº¤æ˜“æ—¶é—´'].str.strip('"').apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S').strftime('%Y/%m/%d %H:%M:%S'))  
    df['äº¤æ˜“æ—¶é—´'] = pd.to_datetime(df['äº¤æ˜“æ—¶é—´']).dt.strftime(format_str)
    df['æ”¶/æ”¯'] = df['æ”¶/æ”¯'].map(expense_mapping).fillna(default_expense)
    df['äº¤æ˜“çŠ¶æ€'] = df['äº¤æ˜“çŠ¶æ€'].map(transaction_status_mapping).fillna(default_transaction_status) 

    # åˆ›å»ºæ–°DataFrame ,å¯¹äºä¸å­˜åœ¨çš„æ•°æ®ï¼Œæˆ‘ä»¬å°†å…¶åˆå§‹åŒ–ä¸ºNaN  
    columns = [  
        'äº¤æ˜“æ—¥æœŸ', 'äº¤æ˜“ç±»å‹', 'åˆ†ç±»ç»†åŒ–', 'äº¤æ˜“å¯¹æ–¹', 'å•†å“',  
        'æ”¶/æ”¯', 'é‡‘é¢', 'äº¤æ˜“æ–¹å¼', 'äº¤æ˜“çŠ¶æ€', 'äº¤æ˜“è®¢å•å·', 'å¤‡æ³¨'  
    ]  
    df_new = pd.DataFrame(columns=columns)
    df_new['äº¤æ˜“æ—¶é—´'] = df['äº¤æ˜“æ—¶é—´']
    df_new['äº¤æ˜“ç±»å‹'] = df['äº¤æ˜“åˆ†ç±»']
    df_new['åˆ†ç±»ç»†åŒ–'] = np.nan
    df_new['äº¤æ˜“å¯¹æ–¹'] = df['å•†æˆ·åç§°']
    df_new['å•†å“'] = df['äº¤æ˜“è¯´æ˜']
    df_new['æ”¶/æ”¯'] = df['æ”¶/æ”¯']
    df_new['é‡‘é¢'] = df['é‡‘é¢']
    df_new['äº¤æ˜“æ–¹å¼'] = df['æ”¶/ä»˜æ¬¾æ–¹å¼']
    df_new['äº¤æ˜“çŠ¶æ€'] = df['äº¤æ˜“çŠ¶æ€']
    df_new['äº¤æ˜“è®¢å•å·'] = df['äº¤æ˜“è®¢å•å·']
    df_new['å¤‡æ³¨'] = np.nan
    df_new.insert(1, 'æ¥æº', "äº¬ä¸œ", allow_duplicates=True)  # æ·»åŠ äº¬ä¸œæ¥æºæ ‡è¯†
    len3 = len(df_new)
    print("æˆåŠŸè¯»å– " + str(len3) + " æ¡ã€Œäº¬ä¸œã€è´¦å•æ•°æ®\n")
    print(df_new)
    return df_new
# ç»Ÿä¸€äº¤æ˜“ç±»å‹
def handlefunc(init_data):
    for index, row in init_data.iterrows():
        if row['äº¤æ˜“ç±»å‹'] == 'é¤é¥®ç¾é£Ÿ':
            row['äº¤æ˜“ç±»å‹'] = 'é¤é¥®é›¶é£Ÿ'
        elif row['äº¤æ˜“ç±»å‹'] == 'å•†æˆ·æ¶ˆè´¹' and row['äº¤æ˜“å¯¹æ–¹'] == 'LAWSON':
            row['äº¤æ˜“ç±»å‹'] = 'é¤é¥®é›¶é£Ÿ'
        else:
            row['äº¤æ˜“çŠ¶æ€'] = 'å…¶ä»–'
            print("ç¬¬" + str(index) + "è¡Œæ•°æ®æœ‰è¯¯ï¼Œè¯·æ£€æŸ¥ï¼")
    return init_data

def handle_total_data(data):
    print("æ‰€æœ‰åˆ—å:", data.columns.tolist())

    # åˆ é™¤åä¸ºâ€œäº¤æ˜“å•å·â€çš„åˆ—
    if 'äº¤æ˜“å•å·' in data.columns:
        data = data.drop(columns=['äº¤æ˜“å•å·'])
        print("åˆ é™¤åˆ—åçš„æ‰€æœ‰åˆ—å:", data.columns.tolist())
    else:
        print("åˆ—'äº¤æ˜“å•å·'ä¸å­˜åœ¨")


    data.reset_index(drop=True, inplace=True)

    # åˆ é™¤æ”¶æ”¯åˆ—ç©ºç™½è¡Œ
    to_drop_1 = data[data['æ”¶/æ”¯'].isin(['/', 'ä¸è®¡æ”¶æ”¯'])].index
    rows_to_drop_1 = data.loc[to_drop_1]
    # print(rows_to_drop_1)
    data = data.drop(to_drop_1).reset_index(drop=True)

    # åˆ é™¤äº¤æ˜“çŠ¶æ€æ— æ•ˆçš„è¡Œ
    conditions_to_drop = ['ç­‰å¾…ç¡®è®¤æ”¶è´§','æç°å·²åˆ°è´¦', 'å·²å…¨é¢é€€æ¬¾', 'å·²é€€æ¬¾','å……å€¼å®Œæˆ', 'é€€æ¬¾æˆåŠŸ', 'è¿˜æ¬¾æˆåŠŸ', 'äº¤æ˜“å…³é—­']
    to_drop_2 = data[data['äº¤æ˜“çŠ¶æ€'].isin(conditions_to_drop)].index
    rows_to_drop_2 = data.loc[to_drop_2]
    # print(rows_to_drop_2)
    data = data.drop(to_drop_2).reset_index(drop=True)
    return data,rows_to_drop_1,rows_to_drop_2



if __name__ == '__main__':
    path_write = "this_mounth_bill.xlsx" # è´¦å•è¾“å‡ºè·¯å¾„
    # è´¦å•è·¯å¾„
    path_wx = "å¾®ä¿¡æ”¯ä»˜è´¦å•(20240401-20240430).csv"
    path_zfb = "alipay_record_20240602_145614.csv"
    path_jd = "bill_20240513233706431_55.csv"

    # è¯»å–åˆå§‹æ•°æ®
    data_wx = read_data_wx(path_wx)
    data_zfb = read_data_zfb(path_zfb)
    data_jd = read_data_jd(path_jd)

    # ä¸Šä¸‹æ‹¼æ¥åˆå¹¶è¡¨æ ¼
    # init_data_merge = pd.concat([data_jd], axis=0)
    init_data_merge = pd.concat([data_wx, data_zfb,data_jd], axis=0)

    # å¤„ç†ç»Ÿä¸€äº¤æ˜“ç±»å‹
    
    handled_data_merge,drop_1,drop_2 = handle_total_data(init_data_merge)

    # åˆ›å»ºè´¦å•
    workbook = openpyxl.Workbook(path_write)  # openpyxlè¯»å–è´¦æœ¬æ–‡ä»¶
    sheet = workbook.active # è·å–é»˜è®¤çš„å·¥ä½œè¡¨
    data_head = init_data_merge.columns.tolist()
    sheet = workbook.create_sheet(title='init-detial') # åˆ›å»ºä¸€ä¸ªæ–°çš„å·¥ä½œè¡¨
    sheet2 = workbook.create_sheet(title='handled-detial') # åˆ›å»ºä¸€ä¸ªæ–°çš„å·¥ä½œè¡¨
    sheet3 = workbook.create_sheet(title='droped-detial') # åˆ›å»ºä¸€ä¸ªæ–°çš„å·¥ä½œè¡¨
    sheet.append(data_head)
    sheet2.append(data_head)
    sheet3.append(data_head)
    # maxrow = sheet._max_row  # è·å–æœ€å¤§è¡Œ
    # print('\nã€Œæ˜ç»†ã€ sheet é¡µå·²æœ‰ ' + str(maxrow) + ' è¡Œæ•°æ®ï¼Œå°†åœ¨æœ«å°¾å†™å…¥æ•°æ®')
    merge_list = init_data_merge.values.tolist()  # æ ¼å¼è½¬æ¢ï¼ŒDataFrame->List
    for row in merge_list:
        sheet.append(row)  # openpyxlå†™æ–‡ä»¶

    now = datetime.datetime.now()
    now = 'ğŸ‘†å¯¼å…¥æ—¶é—´ï¼š' + str(now.strftime('%Y-%m-%d %H:%M:%S'))
    break_lines = [now, '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
    sheet.append(break_lines)

    handled_merge_list = handled_data_merge.values.tolist()  # æ ¼å¼è½¬æ¢ï¼ŒDataFrame->List
    for row in handled_merge_list:
        sheet2.append(row)  # openpyxlå†™æ–‡ä»¶
    sheet2.append(break_lines)

    droped_1_list = drop_1.values.tolist()  # æ ¼å¼è½¬æ¢ï¼ŒDataFrame->List
    for row in droped_1_list:
        sheet3.append(row)  # openpyxlå†™æ–‡ä»¶
    now = 'ä»¥ä¸Šè¡Œç”±äºæ”¶æ”¯æ— æ•ˆè¢«åˆ é™¤'
    break_lines = [now, '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
    brank_lines = ['==', '==', '==', '==', '==', '==', '==', '==', '==', '==', '==', '==']
    sheet3.append(break_lines)
    sheet3.append(brank_lines)

    droped_2_list = drop_2.values.tolist()  # æ ¼å¼è½¬æ¢ï¼ŒDataFrame->List
    for row in droped_2_list:
        sheet3.append(row)  # openpyxlå†™æ–‡ä»¶
    now = 'ä»¥ä¸Šè¡Œç”±äºäº¤æ˜“çŠ¶æ€æ— æ•ˆè¢«åˆ é™¤'
    break_lines = [now, '-', '-', '-', '-', '-', '-', '-', '-', '-', '-', '-']
    sheet3.append(break_lines)

    workbook.save(path_write)  # ä¿å­˜
    print("\næˆåŠŸå°†æ•°æ®å†™å…¥åˆ° " + path_write)
    print("\nè¿è¡ŒæˆåŠŸï¼write successfully!")
    exit(1)